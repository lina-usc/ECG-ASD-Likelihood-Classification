{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#factrozie labels import numpy as np\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal,io,fftpack\n",
    "import pandas as pd\n",
    "import mne\n",
    "from path import Path\n",
    "import numpy as np\n",
    "import neurokit2 as nk \n",
    "filepath = Path('Results2023/')  \n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV\n",
    "from sklearn.metrics import *\n",
    "df_for_classification = pd.read_csv('df_30_classification2023.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ea0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df_for_classification.iloc[ :, -1]\n",
    "X_v=df_for_classification.iloc[:, 2:-1] \n",
    "X = X_v.drop(columns = ['MeanNN','MaxNN', 'MinNN'])\n",
    "#LL 0 , EL 1                               \n",
    "X                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f09b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV\n",
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "parameters = {'n_estimators': [1,10,20,30], 'learning_rate' : [0.01,0.05,0.1,0.5],\n",
    "           'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,30]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify =y, random_state=30)    \n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(random_state=3000), parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.best_estimator_.predict(X_test)\n",
    "print(\"Roc-Auc:\", roc_auc_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "rs = StratifiedShuffleSplit(n_splits = 100, train_size = 0.8, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "roc_auc = []\n",
    "aucc = []\n",
    "precision = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "df_lime_weights = []\n",
    "\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(rs.split(X,y)):\n",
    "    #print(f\"Fold : {i}\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    clf.best_estimator_.fit(X_train.values, y_train)\n",
    "    pred = clf.best_estimator_.predict(X_test.values)\n",
    "    try:\n",
    "        roc =roc_auc_score(y_test, pred,average='macro')\n",
    "        auc = accuracy_score(y_test,pred)\n",
    "        prc = precision_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        rec = recall_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        f1 = f1_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "\n",
    "   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    roc_auc.append(roc)\n",
    "    aucc.append(auc)\n",
    "    precision.append(prc)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    " \n",
    "    \n",
    "df_res = pd.DataFrame([aucc, roc_auc, precision, recalls, f1s]).T\n",
    "df_res.columns = ['Accuracy', 'roc_auc', 'Precision', 'Recall', 'f1']    \n",
    " \n",
    "df_res.to_csv('Results2023/30ClassificationRes/df_30GB.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d32fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#Extra Tree Classifier\n",
    "parameters = { 'n_estimators': [1,10,100], \n",
    "           'criterion' : ['gini', 'entropy'] ,\n",
    "           'max_depth': [1,5,10,20,], \n",
    "           'max_features': ['sqrt','log2'],\n",
    "           'min_samples_split': [2,5,10],\n",
    "           'n_jobs': [-1]}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify =y, random_state=30)    \n",
    "\n",
    "clf = GridSearchCV( ExtraTreesClassifier(random_state=0), parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "pred = clf.best_estimator_.predict(X_test)\n",
    "print(\"Roc-Auc:\", roc_auc_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebcf2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "rs = StratifiedShuffleSplit(n_splits = 100, train_size = 0.8, test_size = 0.2, random_state = 0)\n",
    " \n",
    "roc_auc = []\n",
    "aucc = []\n",
    "precision = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "df_lime_weights = []\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(rs.split(X,y)):\n",
    "    #print(f\"Fold : {i}\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    clf.best_estimator_.fit(X_train, y_train)\n",
    "    pred = clf.best_estimator_.predict(X_test)\n",
    "    try:\n",
    "        roc =roc_auc_score(y_test, pred,average='macro')\n",
    "        auc = accuracy_score(y_test,pred)\n",
    "        prc = precision_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        rec = recall_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        f1 = f1_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "\n",
    "\n",
    "   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    roc_auc.append(roc)\n",
    "    aucc.append(auc)\n",
    "    precision.append(prc)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "df_res = pd.DataFrame([aucc, roc_auc, precision, recalls, f1s]).T\n",
    "df_res.columns = ['Accuracy', 'roc_auc', 'Precision', 'Recall', 'f1']    \n",
    " \n",
    "df_res.to_csv('Results2023/30ClassificationRes/df_30ET.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465143e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Random Forest Classifier \n",
    "parameters = {'n_estimators': [1,10,100,200],\n",
    "          'max_depth': [1,5,10,20], \n",
    "          'max_features': ['sqrt','log2'],\n",
    "          'min_samples_split': [2,5,10], 'n_jobs': [-1]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify =y, random_state=80)    \n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=0), parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.best_estimator_.predict(X_test)\n",
    "print(\"Roc-Auc:\", roc_auc_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "rs = StratifiedShuffleSplit(n_splits = 100, train_size = 0.8, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "roc_auc = []\n",
    "aucc = []\n",
    "precision = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "df_lime_weights = []\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(rs.split(X,y)):\n",
    "    #print(f\"Fold : {i}\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    clf.best_estimator_.fit(X_train, y_train)\n",
    "    pred = clf.best_estimator_.predict(X_test)\n",
    "    try:\n",
    "        roc =roc_auc_score(y_test, pred,average='macro')\n",
    "        auc = accuracy_score(y_test,pred)\n",
    "        prc = precision_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        rec = recall_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        f1 = f1_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    roc_auc.append(roc)\n",
    "    aucc.append(auc)\n",
    "    precision.append(prc)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "df_res = pd.DataFrame([aucc, roc_auc, precision, recalls, f1s]).T\n",
    "df_res.columns = ['Accuracy', 'roc_auc', 'Precision', 'Recall', 'f1']    \n",
    " \n",
    "df_res.to_csv('Results2023/30ClassificationRes/df_30RF.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Ada Boost Classifier\n",
    "parameters = {'algorithm': ['SAMME', 'SAMME.R'],\n",
    "           'n_estimators': [1,10,100]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify =y, random_state=30)    \n",
    "\n",
    "clf = GridSearchCV(AdaBoostClassifier(random_state=0), parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.best_estimator_.predict(X_test)\n",
    "print(\"Roc-Auc:\", roc_auc_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1546f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "roc_auc = []\n",
    "accuracy = []\n",
    "\n",
    "\n",
    "rs = StratifiedShuffleSplit(n_splits = 100, train_size = 0.50, test_size = 0.50, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "roc_auc = []\n",
    "aucc = []\n",
    "precision = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "df_lime_weights = []\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(rs.split(X,y)):\n",
    "    #print(f\"Fold : {i}\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    clf.best_estimator_.fit(X_train, y_train)\n",
    "    pred = clf.best_estimator_.predict(X_test)\n",
    "    try:\n",
    "        roc =roc_auc_score(y_test, pred,average='macro')\n",
    "        auc = accuracy_score(y_test,pred)\n",
    "        prc = precision_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        rec = recall_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        f1 = f1_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "\n",
    "   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    roc_auc.append(roc)\n",
    "    aucc.append(auc)\n",
    "    precision.append(prc)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "df_res = pd.DataFrame([aucc, roc_auc, precision, recalls, f1s]).T\n",
    "df_res.columns = ['Accuracy', 'roc_auc', 'Precision', 'Recall', 'f1']    \n",
    " \n",
    "df_res.to_csv('Results2023/30ClassificationRes/df_30ADB.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "parameters = {'criterion': ['gini', 'entropy'], \n",
    "           'max_depth': [1,5,10,20],\n",
    "           'max_features': [2,5,7],\n",
    "           'min_samples_split': [2,5,10]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify =y, random_state=30)    \n",
    "\n",
    "clf = GridSearchCV(DecisionTreeClassifier(random_state=0), parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.best_estimator_.predict(X_test)\n",
    "print(\"Roc-Auc:\", roc_auc_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd311294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "roc_auc = []\n",
    "accuracy = []\n",
    "\n",
    "\n",
    "rs = StratifiedShuffleSplit(n_splits = 100, train_size = 0.8, test_size = 0.2, random_state = 0)\n",
    "\n",
    "roc_auc = []\n",
    "aucc = []\n",
    "precision = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "df_lime_weights = []\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(rs.split(X,y)):\n",
    "    #print(f\"Fold : {i}\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    clf.best_estimator_.fit(X_train, y_train)\n",
    "    pred = clf.best_estimator_.predict(X_test)\n",
    "    try:\n",
    "        roc =roc_auc_score(y_test, pred,average='macro')\n",
    "        auc = accuracy_score(y_test,pred)\n",
    "        prc = precision_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        rec = recall_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        f1 = f1_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    roc_auc.append(roc)\n",
    "    aucc.append(auc)\n",
    "    precision.append(prc)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "df_res = pd.DataFrame([aucc, roc_auc, precision, recalls, f1s]).T\n",
    "df_res.columns = ['Accuracy', 'roc_auc', 'Precision', 'Recall', 'f1']    \n",
    "\n",
    "df_res.to_csv('Results2023/30ClassificationRes/df_30DT.csv', index=False)   \n",
    "\n",
    "print(np.mean(roc_auc)*100.0)\n",
    "print( np.std(roc_auc)*100.0)\n",
    "\n",
    "print(np.mean(accuracy)*100.0)\n",
    "print( np.std(accuracy)*100.0)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#KNeighborsClassifier\n",
    "parameters = {'n_neighbors': [1,5,10],\n",
    "            'weights': ['uniform','distance'],\n",
    "            'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify =y, random_state=30)    \n",
    "\n",
    "clf = GridSearchCV(KNeighborsClassifier(), parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.best_estimator_.predict(X_test)\n",
    "print(\"Roc-Auc:\", roc_auc_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08487453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "roc_auc = []\n",
    "aucc = []\n",
    "\n",
    "\n",
    "rs = StratifiedShuffleSplit(n_splits = 100, train_size = 0.8, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "roc_auc = []\n",
    "aucc = []\n",
    "precision = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "df_lime_weights = []\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(rs.split(X,y)):\n",
    "    #print(f\"Fold : {i}\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    clf.best_estimator_.fit(X_train, y_train)\n",
    "    pred = clf.best_estimator_.predict(X_test)\n",
    "    try:\n",
    "        roc =roc_auc_score(y_test, pred,average='macro')\n",
    "        auc = accuracy_score(y_test,pred)\n",
    "        prc = precision_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        rec = recall_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        f1 = f1_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    roc_auc.append(roc)\n",
    "    aucc.append(auc)\n",
    "    precision.append(prc)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    \n",
    "df_res = pd.DataFrame([aucc, roc_auc, precision, recalls, f1s]).T\n",
    "df_res.columns = ['Accuracy', 'roc_auc', 'Precision', 'Recall', 'f1']    \n",
    " \n",
    "df_res.to_csv('Results2023/30ClassificationRes/df_30KNN.csv', index=False)   \n",
    "\n",
    "print(np.mean(roc_auc)*100.0)\n",
    "print( np.std(roc_auc)*100.0)\n",
    "\n",
    "print(np.mean(aucc)*100.0)\n",
    "print( np.std(aucc)*100.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e148cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(60, 220, 40),\n",
    "    'learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify =y, random_state=30)    \n",
    "\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "clf = GridSearchCV(xgb_classifier, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.best_estimator_.predict(X_test)\n",
    "print(\"Roc-Auc:\", roc_auc_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250bc0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "roc_auc = []\n",
    "accuracy = []\n",
    "\n",
    "\n",
    "rs = StratifiedShuffleSplit(n_splits = 100, train_size = 0.8, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "roc_auc = []\n",
    "aucc = []\n",
    "precision = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "df_lime_weights = []\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(rs.split(X,y)):\n",
    "    #print(f\"Fold : {i}\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    clf.best_estimator_.fit(X_train, y_train)\n",
    "    pred = clf.best_estimator_.predict(X_test)\n",
    "    try:\n",
    "        roc =roc_auc_score(y_test, pred,average='macro')\n",
    "        auc = accuracy_score(y_test,pred)\n",
    "        prc = precision_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        rec = recall_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        f1 = f1_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    roc_auc.append(roc)\n",
    "    aucc.append(auc)\n",
    "    precision.append(prc)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "df_res = pd.DataFrame([aucc, roc_auc, precision, recalls, f1s]).T\n",
    "df_res.columns = ['Accuracy', 'roc_auc', 'Precision', 'Recall', 'f1']    \n",
    " \n",
    "\n",
    "df_res.to_csv('Results2023/30ClassificationRes/df_30XGB.csv', index=False)   \n",
    "\n",
    "    \n",
    "\n",
    "print(np.mean(roc_auc)*100.0)\n",
    "print( np.std(roc_auc)*100.0)\n",
    "\n",
    "print(np.mean(accuracy)*100.0)\n",
    "print( np.std(accuracy)*100.0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parameters = {'hidden_layer_sizes': [(100,200,), (10)],\n",
    "                'activation': ['tanh', 'relu', 'logistic'],\n",
    "                'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "                'alpha': [0, 0.0001, 0.05],\n",
    "                'learning_rate': ['constant','adaptive']\n",
    "}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify =y, random_state=30)    \n",
    "\n",
    "\n",
    "mlp = MLPClassifier(max_iter= 100, random_state=0) \n",
    "\n",
    "clf = GridSearchCV(mlp, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "pred = clf.best_estimator_.predict(X_test)\n",
    "print(\"Roc-Auc:\", roc_auc_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "roc_auc = []\n",
    "\n",
    "\n",
    "rs = StratifiedShuffleSplit(n_splits = 100, train_size = 0.8, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "roc_auc = []\n",
    "aucc = []\n",
    "precision = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "df_lime_weights = []\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(rs.split(X,y)):\n",
    "    #print(f\"Fold : {i}\")\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    clf.best_estimator_.fit(X_train, y_train)\n",
    "    pred = clf.best_estimator_.predict(X_test)\n",
    "    try:\n",
    "        roc =roc_auc_score(y_test, pred,average='macro')\n",
    "        auc = accuracy_score(y_test,pred)\n",
    "        prc = precision_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        rec = recall_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        f1 = f1_score(y_true=y_test,y_pred=pred,average='macro')\n",
    "        \n",
    "\n",
    "\n",
    "   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    roc_auc.append(roc)\n",
    "    aucc.append(auc)\n",
    "    precision.append(prc)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "df_res = pd.DataFrame([aucc, roc_auc, precision, recalls, f1s]).T\n",
    "df_res.columns = ['Accuracy', 'roc_auc', 'Precision', 'Recall', 'f1']    \n",
    " \n",
    "\n",
    "\n",
    "df_res.to_csv('Results2023/30ClassificationRes/df_30MLP.csv', index=False)   \n",
    "\n",
    "    \n",
    "\n",
    "print(np.mean(roc_auc)*100.0)\n",
    "print( np.std(roc_auc)*100.0)\n",
    "\n",
    "print(np.mean(accuracy)*100.0)\n",
    "print( np.std(accuracy)*100.0)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
