{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646e32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from scipy import signal,io,fftpack\n",
    "import pandas as pd\n",
    "import mne\n",
    "import pickle\n",
    "import neurokit2 as nk\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import heartpy as hp\n",
    "from scipy.stats import lognorm\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Reading path for edf\n",
    "root_edf_path = Path(\"/Users/deepatilwani/Documents/Autism/NewAnalysis/edfFiles_threeToSix\")\n",
    "        \n",
    "edf_paths = list(root_edf_path.glob(\"*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e8ac5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list file and directories\n",
    "res = os.listdir(root_edf_path)\n",
    "res = pd.DataFrame(res)\n",
    "for i, j  in res.iterrows(): \n",
    "        res.loc[i, 0] =j[0].split('/')[-1].split('_')[0]\n",
    "        \n",
    "#finding all unique id's\n",
    "uniqueid = pd.DataFrame(np.unique(res)).astype(int)\n",
    "uniqueid.columns = ['Id']\n",
    "\n",
    "#labels LL EL \n",
    "InfoLabels = pd.read_excel('ParticipantLabels_13sept2022.xlsx')\n",
    "InfoLabels.dropna(inplace=True)\n",
    "\n",
    "InfoLabels.columns = ['Id', 'Status']\n",
    "\n",
    "uniqueid_labels = uniqueid.merge(InfoLabels, on ='Id')\n",
    "#uniqueid_labels\n",
    "#Total participants 115 (all EL, LL, PT and other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e7f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We have other groups than typically developed and elevated developed ... \n",
    "#Extracting the Typical (LL) and elevated  (EL ) labels and id's \n",
    "\n",
    "idsLLandEL = pd.DataFrame(uniqueid_labels[(uniqueid_labels['Status'] == 'LL') | (uniqueid_labels['Status'] == 'EL-SIB')])\n",
    "\n",
    "\n",
    "idsLLandEL.to_csv('FinalIdswithLLandEL.csv', index= False)\n",
    "\n",
    "#82  total participants after rejecting the PT and other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a658c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LL        39\n",
       "EL-SIB    31\n",
       "Name: Status, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elll = pd.read_csv('FinalIdswithLLandEL.csv')\n",
    "elll['Status'].value_counts()\n",
    "\n",
    "#Files with no PIX and OIX \n",
    "#[1001, 1003, 1004, 1028, 1031, 1035, 1036, 1037, 1041, 1042, 1048, 1076]\n",
    "\n",
    "\n",
    "#finding index \n",
    "\n",
    "index_ = elll.loc[elll['Id'].isin([1001, 1003, 1004, 1028, 1031, 1035, 1036, 1037, 1041, 1042, 1048, 1076])].index\n",
    "\n",
    "\n",
    "ell = elll.drop(index_)\n",
    "ell['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832d2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the segments : OIX and PIX\n",
    "\n",
    "#OIX : Object Interaction\n",
    "#PIX : Parent Interaction\n",
    "\n",
    "def get_segments(path_edf, seconds, **kwargs):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Input \n",
    "    \n",
    "        path_edf : path to folder where all EDF files are stored\n",
    "    \n",
    "        seconds : We are dividing the segments into 30s,60s,90s,120s and 0(for full length) \n",
    "    \n",
    "    \n",
    "    Output \n",
    "        epoch_ecg : Seconds for the ECG segments multipe epochs set of [30,60,90,120,0]  \n",
    "        condition : OIX or PIX\n",
    "        subject   : Participant ID\n",
    "        age       : In 3-6 months\n",
    "        sfreq     : One of these 128,512 or 1024\n",
    "        seconds   : One of these : 30,60,90,120, 0\n",
    "    \n",
    "    Author : Deepa Tilwani dtilwani@mailbox.sc.edu\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # age is in months\n",
    "    \n",
    "    subject, age = path_edf.split('/')[-1].split('_')[0], path_edf.split('/')[-1].split('_')[1][:2]\n",
    "    \n",
    "    #print(subject, age)\n",
    "    \n",
    "    # get_log_times is a function which is extracting timestamps for the OIX and PIX experiments. \n",
    "    \n",
    "    log_df = get_log_times(subject, age, **kwargs)\n",
    "    \n",
    "    #print(log_df)\n",
    "    \n",
    "    #Reading the EDF files\n",
    "    edf_raw = mne.io.read_raw_edf(path_edf, preload=True)\n",
    "    \n",
    "    #Extracting the frequency \n",
    "    sfreq = edf_raw.info[\"sfreq\"]\n",
    "    \n",
    "    #Intial filtering\n",
    "    edf_raw = edf_raw.notch_filter(np.arange(60, sfreq/2.0, 60))\n",
    "    edf_raw = edf_raw.filter(1, sfreq/4.0)\n",
    "\n",
    "    \n",
    "    #print(log_df.condition.values)\n",
    "    \n",
    "    if log_df is not None:\n",
    "        #print(\"in if loop\")\n",
    "        #print(log_df.values)\n",
    "        for i,j in log_df.iterrows(): \n",
    "                #Getting Stat/ stop of the experiment in seconds\n",
    "                start_edf = int(j.start * 60)\n",
    "                stop_edf =  int(j.end * 60)\n",
    "                \n",
    "                #print(start_edf,stop_edf)\n",
    "                \n",
    "                conditions = ['OIX', 'PIX', 'OIX2'] #OIX2 is also same as OIX, naming issues\n",
    "                \n",
    "                if j.condition in conditions:\n",
    "\n",
    "                    if seconds == 0:\n",
    "                        try:\n",
    "                            print(j.condition)\n",
    "\n",
    "                            segments = edf_raw.get_data(\"ECG0\",tmin=start_edf,tmax=stop_edf).squeeze()\n",
    "                            return  segments, j.condition ,subject,age ,  sfreq , seconds\n",
    "\n",
    "                        except :\n",
    "                            segments = edf_raw.get_data(\"ECG\", tmin=start_edf,tmax=stop_edf).squeeze() \n",
    "                            return  segments, j.condition , subject,age,  sfreq, seconds\n",
    "\n",
    "                    else : \n",
    "                    \n",
    "                            print(seconds, start_edf, stop_edf)\n",
    "                            epochs = mne.make_fixed_length_epochs(edf_raw.crop(tmin=start_edf,tmax=stop_edf),\n",
    "\n",
    "                                                              duration=seconds, preload=False)\n",
    "\n",
    "                            df_epoch = epochs.to_data_frame()\n",
    "                            no_of_epoch = df_epoch.epoch.unique() \n",
    "                            #df_epoch have the epoch column which specify which segment the vaue is - 0,1,2 so on\n",
    "                            array_for_epochs = []\n",
    "                            for i in no_of_epoch:\n",
    "                                epoch_ecg = df_epoch.loc[df_epoch['epoch'] == i].T.values\n",
    "                                #Returning values in epoch_ecg ( indices have time, epoch number,segments(epochs))\n",
    "                                return  epoch_ecg, j.condition , subject, age,  sfreq ,seconds \n",
    "                            \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29443a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old torsh timelogs - /Users/deepatilwani/Documents/Autism/NewAnalysis/all_infants_timelogs\n",
    "\n",
    "# There was change in data saving pipeline in later of study. So, we have diffrent styles of time stamps files.\n",
    "\n",
    "\n",
    "# Fuction to get the time logs of experiments OIX/PIX\n",
    "\n",
    "def get_log_times(subject, age, path_timelog_format=\"/Users/deepatilwani/Documents/Autism/NewAnalysis/all_infants_timelogs/{subject}_{age}.csv\",\n",
    "                  datavyu_format=\"/Users/deepatilwani/Documents/Autism/Generated Files_{kind}_03092022_Datavyu_ALLOnly_AI/Stimuli/\" +\n",
    "                                 \"{subject}_{age}_stimulus.csv\"):\n",
    "\n",
    "    # Look first for datavyu times\n",
    "    rows = []\n",
    "    for kind in [\"OIX\", \"PIX\", \"OIX2\"]:\n",
    "        stim_path = Path(datavyu_format.format(kind=kind, subject=subject, age=age))\n",
    "        if stim_path.exists():\n",
    "            csv_file = pd.read_csv(stim_path).dropna()\n",
    "            csv_file.columns = [\"start\", \"end\", \"stimulus\"]\n",
    "            csv_file = csv_file[csv_file.stimulus != \"END\"]\n",
    "            rows.append({\"start\": csv_file.start.min() / 60.0,\n",
    "                         \"end\": csv_file.end.max() / 60.0,\n",
    "                         \"condition\": kind})\n",
    "      \n",
    "    if len(rows):\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    # if datavyu times are not available, look for old time logs\n",
    "    path_timelog = Path(path_timelog_format.format(subject=subject, age=age))\n",
    "    if path_timelog.exists():\n",
    "        csv_file = pd.read_csv(path_timelog).dropna()\n",
    "        csv_file.columns = [\"visit\", \"segment\", \"condition\", \"start\", \"end\"]\n",
    "        csv_file = csv_file[csv_file.end > csv_file.start]\n",
    "        \n",
    "        return csv_file\n",
    "\n",
    "    # No segment logs available\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa17410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to extract the data for all edf files \n",
    "data_extracted =[]\n",
    "COUNT = 0\n",
    "\n",
    "#defining the seconds for segmenting \n",
    "time_seconds  = [0,30,60,90,120]\n",
    "\n",
    "errorfiles = []\n",
    "\n",
    "for i in edf_paths:\n",
    "    \n",
    "    COUNT = COUNT+1\n",
    "    subject = str(i.split('/')[-1].split('_')[0])\n",
    "    age = i.split('/')[-1].split('_')[1][:2]\n",
    "    name = subject+'_'+age\n",
    "    \n",
    "    for time in time_seconds:  \n",
    "            if int(subject) in idsLLandEL[\"Id\"].values: \n",
    "                    try:\n",
    "                        segment, condition, edf_id, month, sfreq, seconds= get_segments(i,seconds=time ) \n",
    "\n",
    "                        data_extracted.append({ \"Id\" :edf_id,\"month\": month,\"freq\":sfreq,\"segments\":segment, \"condition\" : condition,\n",
    "                                                     'segment_lenInSec': seconds}) \n",
    "                    except:\n",
    "\n",
    "                        errorfiles.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "916d36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_extracted is the variable name which have all edf's data \n",
    "\n",
    "# Converting into Dataframe\n",
    "\n",
    "df = pd.DataFrame(data_extracted)\n",
    "df = df.sort_values('Id').reset_index(drop=True)\n",
    "\n",
    "#Saving it to pickel for later use\n",
    "df.to_pickle(\"extracted_data_paper2023.pkl\") \n",
    "\n",
    "\n",
    "#reading pickel\n",
    "df_pickel = pd.read_pickle(\"extracted_data_paper2023.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d43fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_preprocess = []\n",
    "\n",
    "df_pickel = df_pickel.sort_values(by = ['Id', 'segment_lenInSec'])\n",
    "\n",
    "for i,j in df_pickel.iterrows():\n",
    "    print(j)\n",
    "  \n",
    "    if not j['segment_lenInSec'] in [30,60,90,120]:\n",
    "          print(j['segments'][3:])\n",
    "        \n",
    "          df_for_preprocess.append({ \"Id\" :j['Id'],\"month\": j['month'],\"freq\":j['freq'],\n",
    "                               \"segments\":j['segments'][3:], \"condition\" : j['condition'],\n",
    "                                      'segment_lenInSec': 0})\n",
    "            \n",
    "    else : \n",
    "        for x in j['segments'][3:]:\n",
    "\n",
    "              df_for_preprocess.append({ \"Id\" :j['Id'],\"month\": j['month'],\"freq\":j['freq'],\n",
    "                                   \"segments\":x, \"condition\" : j['condition'],\n",
    "                                          'segment_lenInSec': j['segment_lenInSec']})\n",
    "            \n",
    "          \n",
    "df_for_preprocess = pd.DataFrame(df_for_preprocess)\n",
    "df_for_preprocess.to_pickle(\"df_for_preprocess2023.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3582e0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "528\n",
      "528\n",
      "528\n",
      "528\n"
     ]
    }
   ],
   "source": [
    "#To check the segments in each length \n",
    "\n",
    "df_for_preprocess = pd.read_pickle(\"df_for_preprocess2023.pkl\")\n",
    "\n",
    "grouped_df = df_for_preprocess.groupby('segment_lenInSec')\n",
    "\n",
    "for key, item in grouped_df:\n",
    "    if key==0:\n",
    "        df_0 = grouped_df.get_group(0)\n",
    "        print(len(df_0))\n",
    "    if key==30:\n",
    "        df_30 = grouped_df.get_group(30)\n",
    "        print(len(df_30))\n",
    "    if key==60:\n",
    "        df_60 = grouped_df.get_group(60)\n",
    "        print(len(df_60))\n",
    "    if key==90:\n",
    "        df_90 = grouped_df.get_group(90)\n",
    "        print(len(df_90))\n",
    "    if key==120:\n",
    "        df_120 = grouped_df.get_group(120)\n",
    "        print(len(df_120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "577fb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to Preprocess ECG files.\n",
    "\n",
    "def get_outliers(vals, k=3):\n",
    "    q1, q2, q3 = np.percentile(vals, [25, 50, 75])\n",
    "    return (vals < q2 - k * (q3 - q1)) | (vals > q2 + k * (q3 - q1))\n",
    "\n",
    "\n",
    "def process_ecg_data_segment(rec_ecg, sfreq, margin=250, debug=False, resample=None, **kwargs):\n",
    "    if len(rec_ecg) == 0:\n",
    "        return\n",
    "\n",
    "    if resample is not None and resample != sfreq:\n",
    "        rec_ecg = mne.filter.resample(rec_ecg, up=resample/sfreq)\n",
    "        sfreq = resample\n",
    "\n",
    "            \n",
    "    try:\n",
    "        # Using heartpy library to extract the Rpeaks\n",
    "        wd, m = hp.process(rec_ecg, sfreq, **kwargs)\n",
    "    except hp.exceptions.BadSignalWarning:\n",
    "        return\n",
    "\n",
    "    beats = []\n",
    "    peaks, peaks_y = np.array([[peak, peak_y] for peak, peak_y in zip(wd[\"peaklist\"], wd[\"ybeat\"])\n",
    "                               if peak not in wd[\"removed_beats\"]]).T\n",
    "    peaks = peaks.astype(int)\n",
    "\n",
    "    p1s, p2s, p3s = peaks[:-2], peaks[1:-1], peaks[2:]\n",
    "    for p1, p2, p3 in zip(p1s, p2s, p3s):\n",
    "        x = np.arange(p1, p3 + 1)\n",
    "        y = rec_ecg[p1:(p3 + 1)]\n",
    "        f = interpolate.interp1d(x, y)\n",
    "\n",
    "        xnew = np.concatenate((np.linspace(p1, p2, margin), np.linspace(p2, p3, margin)))\n",
    "        ynew = f(xnew)  # use interpolation function returned by `interp1d`\n",
    "        beats.append(ynew)\n",
    "\n",
    "    beats = np.array(beats)\n",
    "\n",
    "    if len(beats) == 0:\n",
    "        return\n",
    "    residuals = np.trapz((beats - beats.mean(0)) ** 2, axis=1)\n",
    "    outliers = get_outliers(residuals, k=6)\n",
    "\n",
    "    nb_samples = np.median((p3s - p1s)[~outliers])\n",
    "\n",
    "    # Flagging as outliers P2 to close to the borders\n",
    "    outliers |= ((p2s - nb_samples // 2).astype(int) < 0)\n",
    "    outliers |= ((p2s + nb_samples // 2).astype(int) >= len(rec_ecg))\n",
    "\n",
    "    additional_removed_beats = np.array(peaks)[np.concatenate([[True], outliers, [True]])]\n",
    "    additional_removed_beats_y = np.array(peaks_y)[np.concatenate([[True], outliers, [True]])]\n",
    "\n",
    "    clean_beats = beats[~outliers, :]\n",
    "\n",
    "    raw_beats = np.array([rec_ecg[int(p2 - nb_samples // 2):int(p2 + nb_samples // 2)]\n",
    "                          for p2 in p2s[~outliers]])\n",
    "\n",
    "    raw_t = np.arange(-int(nb_samples // 2), int(nb_samples // 2)) / sfreq\n",
    "\n",
    "    #if clean_beats.shape[0] < 20:\n",
    "       # return\n",
    "\n",
    "    wd_copy = wd.copy()\n",
    "\n",
    "    wd_copy[\"removed_beats\"] = np.array(np.concatenate([wd[\"removed_beats\"], additional_removed_beats]))\n",
    "    wd_copy[\"removed_beats_y\"] = np.array(np.concatenate([wd[\"removed_beats_y\"], additional_removed_beats_y]))\n",
    "    #removed_beats -- > peaklist\n",
    "    #removed_beats_y --> amlitude values of removed peaks\n",
    "    clean_mean_beat = np.median(clean_beats, 0)\n",
    "\n",
    "    signal = np.trapz(clean_mean_beat ** 2)\n",
    "    noise = np.trapz((clean_beats - clean_mean_beat) ** 2, axis=1)\n",
    "\n",
    "    if debug:\n",
    "        plt.figure()\n",
    "        hp.plotter(wd, m, figsize=(20, 4))\n",
    "        plt.xlim(0, 30)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(residuals, \".\")\n",
    "        plt.plot(np.arange(len(residuals))[outliers], residuals[outliers], \".\", color=\"r\")\n",
    "\n",
    "        plt.figure()\n",
    "        hp.plotter(wd_copy, m, figsize=(20, 4))\n",
    "        plt.xlim(0, 30)\n",
    "\n",
    "        plt.figure()\n",
    "        sns.heatmap(clean_beats)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(clean_beats.T, alpha=0.1, color='k')\n",
    "        plt.plot(clean_mean_beat, color=\"r\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    return {\"SNR\": np.mean(10 * np.log10(signal / noise)),\n",
    "    \"mean_beat\": clean_mean_beat,\n",
    "    \"nb_valid_beats\": clean_beats.shape[0],\n",
    "    \"nb_invalid_beats\": np.sum(outliers),\n",
    "    # \"file_parts\": file_name.name.replace(\".edf\", \"\").split(\"_\"),\n",
    "    \"wd\": wd,\n",
    "    \"wd_copy\": wd_copy, \n",
    "    \"clean_beats\": clean_beats, #beats\n",
    "    \"raw_beats\": raw_beats,\n",
    "    \"raw_t\": raw_t,\n",
    "    \"rel_p1\": p2s[~outliers] - p1s[~outliers],\n",
    "    \"rel_p3\": p3s[~outliers] - p2s[~outliers],\n",
    "    \"sfreq\": sfreq}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89419728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this using the windowing for ECG (60s, 120s)\n",
    "\n",
    "import scipy.interpolate as spi\n",
    "\n",
    "\n",
    "invalid_segment_id = []\n",
    "hrv_all = []\n",
    "\n",
    "results_df = []\n",
    "COUNT = 0\n",
    "removedbeats = []\n",
    "cleanbeats_list =[]\n",
    "no_of_cleanbeats = []\n",
    "perc_of_newbeats = []\n",
    "for idx,row in df_for_preprocess.iterrows():\n",
    "     #print(row)\n",
    "    #preprocessing of the segments\n",
    "  \n",
    "    \n",
    "    try :\n",
    "        COUNT = COUNT+1\n",
    "        #print(row['Id'],row['month'])\n",
    "        \n",
    "        pro = process_ecg_data_segment(row['segments'],sfreq=row['freq'],debug=False) #no resampling\n",
    "        cleanbeats = [i for i in pro['wd_copy']['peaklist'] if i not in pro['wd_copy']['removed_beats']]\n",
    "        cleanbeats_list.append(cleanbeats)\n",
    "        removedbeats.append(pro['wd_copy']['removed_beats'])\n",
    "        #print(\"Clean Beats :\", len(cleanbeats))\n",
    "        no_of_cleanbeats.append(len(cleanbeats))\n",
    "        \n",
    "        #Calculations for new beats interpolation percentage\n",
    "        med_ibi = np.median(np.diff(cleanbeats))\n",
    "        ibis = np.diff(cleanbeats)\n",
    "        #print(ibis)\n",
    "        nb_ibi = np.round(ibis/med_ibi).astype(int)\n",
    "        #print(nb_ibi)\n",
    "\n",
    "        x = np.cumsum(nb_ibi)[nb_ibi == 1]\n",
    "        y = np.array(cleanbeats[1:])[nb_ibi == 1]\n",
    "        f = spi.interp1d(x,y,kind = \"linear\",fill_value=\"extrapolate\")\n",
    "        xnew = np.arange(1, np.cumsum(nb_ibi)[-1]+1)\n",
    "        new_peaks = np.round(f(xnew)) \n",
    "\n",
    "        #percentage of new beat\n",
    "        perc = int((len(new_peaks)-len(cleanbeats))* 100/len(cleanbeats))\n",
    "        #print(\"percentage of new beats :\", perc)\n",
    "\n",
    "        perc_of_newbeats.append(perc)\n",
    "\n",
    "        if perc <=30:\n",
    "            if len(cleanbeats) >= 30:\n",
    "                #print(\"Increased percentage of peaks <= 30%\", row['Id'],row['month'])            \n",
    "\n",
    "\n",
    "\n",
    "                #print(\"NewPeaks\",len(new_peaks))\n",
    "                #print(\"Actual Cleaned Beats\", len(cleanbeats)) \n",
    "\n",
    "                plt.plot(xnew, new_peaks, \".\")\n",
    "                plt.plot(x, y, \".\")\n",
    "                plt.show() \n",
    "                #Extracting HRV values on the basis of rpeak\n",
    "                hrv_feat = nk.hrv(new_peaks, sampling_rate=sfreq, show=False)\n",
    "                results_df.append({ \"Id\" :row['Id'],\n",
    "                                \"Month\" :row['month'] ,\n",
    "                                \"MeanNN\" : hrv_feat['HRV_MeanNN'][0],\n",
    "                                \"MedianNN\": hrv_feat['HRV_MedianNN'][0], \n",
    "                                \"pnn20\": hrv_feat['HRV_pNN20'][0], \n",
    "                                \"sd1sd2\":hrv_feat['HRV_SD1SD2'][0],                                                                                  \n",
    "                                \"CvNN\" : hrv_feat['HRV_CVNN'][0] , \n",
    "                                \"HTI\":hrv_feat['HRV_HTI'][0] , \n",
    "                                \"CSI\" :hrv_feat['HRV_CSI'] [0],\n",
    "                                 \"CVI\":hrv_feat['HRV_CVI'][0],\n",
    "                                  \"MaxNN\" : hrv_feat['HRV_MaxNN'][0],\n",
    "                                  \"MinNN\": hrv_feat['HRV_MinNN'][0],\n",
    "                                \"condition\" : row['condition'],\n",
    "                                \"segment_lenInSec\" : int(row['segment_lenInSec'] )\n",
    "\n",
    "                                 })\n",
    "\n",
    "        \n",
    "    except:\n",
    "        invalid_segment_id.append(str(row['Id'])+'_'+row['month'])\n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03d86646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/71/lpprjh8x2x79bf69xl_jhvy40000gn/T/ipykernel_48881/756361255.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  InfoLabels.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "sorted_result_df = pd.DataFrame(results_df).reset_index(drop=True)\n",
    "\n",
    "#csv file-- for labels\n",
    "ParticipantsInfo = pd.read_csv('ParticipantInfo_nodx.csv')\n",
    "\n",
    "#labels LL EL \n",
    "InfoLabels = ParticipantsInfo[['Participant ID', 'Group']]\n",
    "\n",
    "InfoLabels.dropna(inplace=True)\n",
    "\n",
    "#changing label column names\n",
    "InfoLabels.columns = [ 'Id', 'Labels']\n",
    "sorted_result_df['Id'] = sorted_result_df['Id'].astype(int)\n",
    "\n",
    "df_with_labels_segments = sorted_result_df.merge(InfoLabels, on ='Id')\n",
    "df_with_labels_segments.to_pickle(\"df_with_labels_segments2023.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9c9bd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Month</th>\n",
       "      <th>MeanNN</th>\n",
       "      <th>MedianNN</th>\n",
       "      <th>pnn20</th>\n",
       "      <th>sd1sd2</th>\n",
       "      <th>CvNN</th>\n",
       "      <th>HTI</th>\n",
       "      <th>CSI</th>\n",
       "      <th>CVI</th>\n",
       "      <th>MaxNN</th>\n",
       "      <th>MinNN</th>\n",
       "      <th>condition</th>\n",
       "      <th>segment_lenInSec</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>6m</td>\n",
       "      <td>469.995959</td>\n",
       "      <td>457.031250</td>\n",
       "      <td>22.413793</td>\n",
       "      <td>0.550926</td>\n",
       "      <td>0.197166</td>\n",
       "      <td>3.411765</td>\n",
       "      <td>1.815126</td>\n",
       "      <td>5.038905</td>\n",
       "      <td>738.281250</td>\n",
       "      <td>248.046875</td>\n",
       "      <td>OIX</td>\n",
       "      <td>30</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005</td>\n",
       "      <td>6m</td>\n",
       "      <td>445.312500</td>\n",
       "      <td>447.265625</td>\n",
       "      <td>8.474576</td>\n",
       "      <td>2.008370</td>\n",
       "      <td>0.098908</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>0.497916</td>\n",
       "      <td>4.338518</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>267.578125</td>\n",
       "      <td>OIX</td>\n",
       "      <td>30</td>\n",
       "      <td>LL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007</td>\n",
       "      <td>6m</td>\n",
       "      <td>405.789022</td>\n",
       "      <td>404.296875</td>\n",
       "      <td>1.040312</td>\n",
       "      <td>0.208041</td>\n",
       "      <td>0.042334</td>\n",
       "      <td>4.660606</td>\n",
       "      <td>4.806756</td>\n",
       "      <td>3.270456</td>\n",
       "      <td>498.046875</td>\n",
       "      <td>355.468750</td>\n",
       "      <td>OIX</td>\n",
       "      <td>0</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>6m</td>\n",
       "      <td>408.264160</td>\n",
       "      <td>404.296875</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>0.182949</td>\n",
       "      <td>0.053286</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>5.466006</td>\n",
       "      <td>3.369886</td>\n",
       "      <td>498.046875</td>\n",
       "      <td>380.859375</td>\n",
       "      <td>OIX</td>\n",
       "      <td>30</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1007</td>\n",
       "      <td>6m</td>\n",
       "      <td>396.778682</td>\n",
       "      <td>394.531250</td>\n",
       "      <td>6.164384</td>\n",
       "      <td>0.812934</td>\n",
       "      <td>0.073757</td>\n",
       "      <td>5.840000</td>\n",
       "      <td>1.230112</td>\n",
       "      <td>4.124043</td>\n",
       "      <td>568.359375</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>OIX</td>\n",
       "      <td>60</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>1133</td>\n",
       "      <td>4m</td>\n",
       "      <td>212.861032</td>\n",
       "      <td>212.890625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297049</td>\n",
       "      <td>0.037210</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>3.366453</td>\n",
       "      <td>2.740349</td>\n",
       "      <td>230.468750</td>\n",
       "      <td>199.218750</td>\n",
       "      <td>OIX</td>\n",
       "      <td>30</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>1133</td>\n",
       "      <td>4m</td>\n",
       "      <td>207.938058</td>\n",
       "      <td>207.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228353</td>\n",
       "      <td>0.043336</td>\n",
       "      <td>3.255814</td>\n",
       "      <td>4.379178</td>\n",
       "      <td>2.752455</td>\n",
       "      <td>230.468750</td>\n",
       "      <td>189.453125</td>\n",
       "      <td>OIX</td>\n",
       "      <td>60</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1133</td>\n",
       "      <td>4m</td>\n",
       "      <td>204.228154</td>\n",
       "      <td>203.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202335</td>\n",
       "      <td>0.048234</td>\n",
       "      <td>3.176471</td>\n",
       "      <td>4.942306</td>\n",
       "      <td>2.778268</td>\n",
       "      <td>230.468750</td>\n",
       "      <td>183.593750</td>\n",
       "      <td>OIX</td>\n",
       "      <td>90</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>1133</td>\n",
       "      <td>4m</td>\n",
       "      <td>201.618494</td>\n",
       "      <td>201.171875</td>\n",
       "      <td>0.682594</td>\n",
       "      <td>0.207661</td>\n",
       "      <td>0.053965</td>\n",
       "      <td>3.708861</td>\n",
       "      <td>4.815550</td>\n",
       "      <td>2.878500</td>\n",
       "      <td>230.468750</td>\n",
       "      <td>177.734375</td>\n",
       "      <td>OIX</td>\n",
       "      <td>120</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>1134</td>\n",
       "      <td>4m</td>\n",
       "      <td>227.407095</td>\n",
       "      <td>226.562500</td>\n",
       "      <td>11.196911</td>\n",
       "      <td>1.016885</td>\n",
       "      <td>0.104589</td>\n",
       "      <td>3.278481</td>\n",
       "      <td>0.983395</td>\n",
       "      <td>3.957739</td>\n",
       "      <td>333.984375</td>\n",
       "      <td>121.093750</td>\n",
       "      <td>OIX</td>\n",
       "      <td>120</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id Month      MeanNN    MedianNN      pnn20    sd1sd2      CvNN  \\\n",
       "0    1002    6m  469.995959  457.031250  22.413793  0.550926  0.197166   \n",
       "1    1005    6m  445.312500  447.265625   8.474576  2.008370  0.098908   \n",
       "2    1007    6m  405.789022  404.296875   1.040312  0.208041  0.042334   \n",
       "3    1007    6m  408.264160  404.296875   1.562500  0.182949  0.053286   \n",
       "4    1007    6m  396.778682  394.531250   6.164384  0.812934  0.073757   \n",
       "..    ...   ...         ...         ...        ...       ...       ...   \n",
       "464  1133    4m  212.861032  212.890625   0.000000  0.297049  0.037210   \n",
       "465  1133    4m  207.938058  207.031250   0.000000  0.228353  0.043336   \n",
       "466  1133    4m  204.228154  203.125000   0.000000  0.202335  0.048234   \n",
       "467  1133    4m  201.618494  201.171875   0.682594  0.207661  0.053965   \n",
       "468  1134    4m  227.407095  226.562500  11.196911  1.016885  0.104589   \n",
       "\n",
       "          HTI       CSI       CVI       MaxNN       MinNN condition  \\\n",
       "0    3.411765  1.815126  5.038905  738.281250  248.046875       OIX   \n",
       "1    2.950000  0.497916  4.338518  625.000000  267.578125       OIX   \n",
       "2    4.660606  4.806756  3.270456  498.046875  355.468750       OIX   \n",
       "3    4.266667  5.466006  3.369886  498.046875  380.859375       OIX   \n",
       "4    5.840000  1.230112  4.124043  568.359375  250.000000       OIX   \n",
       "..        ...       ...       ...         ...         ...       ...   \n",
       "464  2.750000  3.366453  2.740349  230.468750  199.218750       OIX   \n",
       "465  3.255814  4.379178  2.752455  230.468750  189.453125       OIX   \n",
       "466  3.176471  4.942306  2.778268  230.468750  183.593750       OIX   \n",
       "467  3.708861  4.815550  2.878500  230.468750  177.734375       OIX   \n",
       "468  3.278481  0.983395  3.957739  333.984375  121.093750       OIX   \n",
       "\n",
       "     segment_lenInSec Labels  \n",
       "0                  30     EL  \n",
       "1                  30     LL  \n",
       "2                   0     EL  \n",
       "3                  30     EL  \n",
       "4                  60     EL  \n",
       "..                ...    ...  \n",
       "464                30     EL  \n",
       "465                60     EL  \n",
       "466                90     EL  \n",
       "467               120     EL  \n",
       "468               120     EL  \n",
       "\n",
       "[469 rows x 15 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"df_with_labels_segments2023.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dab113e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "101\n",
      "92\n",
      "92\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "pd.read_pickle(\"df_with_labels_segments2023.pkl\")\n",
    "grouped_df = pd.read_pickle(\"df_with_labels_segments2023.pkl\").groupby('segment_lenInSec')\n",
    "\n",
    "for key, item in grouped_df:\n",
    "    if key==0:\n",
    "        df_0 = grouped_df.get_group(0)\n",
    "        print(len(df_0))\n",
    "    if key==30:\n",
    "        df_30 = grouped_df.get_group(30)\n",
    "        print(len(df_30))\n",
    "    if key==60:\n",
    "        df_60 = grouped_df.get_group(60)\n",
    "        print(len(df_60))\n",
    "    if key==90:\n",
    "        df_90 = grouped_df.get_group(90)\n",
    "        print(len(df_90))\n",
    "    if key==120:\n",
    "        df_120 = grouped_df.get_group(120)\n",
    "        print(len(df_120))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "decdf6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "61\n",
      "54\n",
      "56\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dfinal = sorted_result_df.copy()\n",
    "dfinal['Id']= dfinal['Id'].astype(int)\n",
    "df_groupby = dfinal.groupby(['Id','segment_lenInSec']).mean()\n",
    "df_groupby\n",
    "#df_for_classification = df_groupby.merge(InfoLabels, on ='Id')\n",
    "#df_for_classification\n",
    "\n",
    "df_copy = df_groupby.reset_index(level=[0,1])\n",
    "\n",
    "grouped_df = df_copy.groupby('segment_lenInSec')\n",
    "\n",
    "for key, item in grouped_df:\n",
    "    if key==0:\n",
    "        df_0 = grouped_df.get_group(0)\n",
    "    if key==30:\n",
    "        df_30 = grouped_df.get_group(30)\n",
    "    if key==60:\n",
    "        df_60 = grouped_df.get_group(60)\n",
    "    if key==90:\n",
    "        df_90 = grouped_df.get_group(90)\n",
    "    if key==120:\n",
    "        df_120 = grouped_df.get_group(120)\n",
    "\n",
    "df_labels_dict = {\"LL\" : 0 , \"EL\" : 1 }\n",
    "\n",
    "df_0_classification = df_0.merge(InfoLabels, on ='Id')\n",
    "df_0_classification['Labels'] = df_0_classification['Labels'].map(df_labels_dict)\n",
    "df_0_classification.to_csv(\"df_0_classification2023.csv\",index=False)\n",
    "print(len(df_0_classification))\n",
    "\n",
    "\n",
    "df_30_classification = df_30.merge(InfoLabels, on ='Id')\n",
    "df_30_classification['Labels'] = df_30_classification['Labels'].map(df_labels_dict)\n",
    "df_30_classification.to_csv(\"df_30_classification2023.csv\",index=False)\n",
    "print(len(df_30_classification))\n",
    "\n",
    "df_60_classification = df_60.merge(InfoLabels, on ='Id')\n",
    "df_60_classification['Labels'] = df_60_classification['Labels'].map(df_labels_dict)\n",
    "df_60_classification.to_csv(\"df_60_classification2023.csv\",index=False)\n",
    "print(len(df_60_classification))\n",
    "\n",
    "df_90_classification = df_90.merge(InfoLabels, on ='Id')\n",
    "df_90_classification['Labels'] = df_90_classification['Labels'].map(df_labels_dict)\n",
    "df_90_classification.to_csv(\"df_90_classification2023.csv\",index=False)\n",
    "print(len(df_90_classification))\n",
    "\n",
    "\n",
    "df_120_classification = df_120.merge(InfoLabels, on ='Id')\n",
    "df_120_classification['Labels'] = df_120_classification['Labels'].map(df_labels_dict)\n",
    "df_120_classification.to_csv(\"df_120_classification2023.csv\",index=False)\n",
    "print(len(df_120_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "192600ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv(\"df_120_classification2023.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d6433d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>segment_lenInSec</th>\n",
       "      <th>MeanNN</th>\n",
       "      <th>MedianNN</th>\n",
       "      <th>pnn20</th>\n",
       "      <th>sd1sd2</th>\n",
       "      <th>CvNN</th>\n",
       "      <th>HTI</th>\n",
       "      <th>CSI</th>\n",
       "      <th>CVI</th>\n",
       "      <th>MaxNN</th>\n",
       "      <th>MinNN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1045.696970</td>\n",
       "      <td>90.0</td>\n",
       "      <td>571.332415</td>\n",
       "      <td>569.138652</td>\n",
       "      <td>11.703802</td>\n",
       "      <td>0.359812</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>5.647090</td>\n",
       "      <td>3.376040</td>\n",
       "      <td>3.674841</td>\n",
       "      <td>704.713147</td>\n",
       "      <td>501.484572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1075.173913</td>\n",
       "      <td>90.0</td>\n",
       "      <td>419.473671</td>\n",
       "      <td>417.091259</td>\n",
       "      <td>8.758629</td>\n",
       "      <td>0.399597</td>\n",
       "      <td>0.062138</td>\n",
       "      <td>5.005218</td>\n",
       "      <td>3.562715</td>\n",
       "      <td>3.574622</td>\n",
       "      <td>520.118603</td>\n",
       "      <td>347.182122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id  segment_lenInSec      MeanNN    MedianNN      pnn20  \\\n",
       "Labels                                                                     \n",
       "0       1045.696970              90.0  571.332415  569.138652  11.703802   \n",
       "1       1075.173913              90.0  419.473671  417.091259   8.758629   \n",
       "\n",
       "          sd1sd2      CvNN       HTI       CSI       CVI       MaxNN  \\\n",
       "Labels                                                                 \n",
       "0       0.359812  0.049437  5.647090  3.376040  3.674841  704.713147   \n",
       "1       0.399597  0.062138  5.005218  3.562715  3.574622  520.118603   \n",
       "\n",
       "             MinNN  \n",
       "Labels              \n",
       "0       501.484572  \n",
       "1       347.182122  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_90count = pd.read_csv('df_90_classification2023.csv')\n",
    "df_90count.groupby('Labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d3ef5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>segment_lenInSec</th>\n",
       "      <th>MeanNN</th>\n",
       "      <th>MedianNN</th>\n",
       "      <th>pnn20</th>\n",
       "      <th>sd1sd2</th>\n",
       "      <th>CvNN</th>\n",
       "      <th>HTI</th>\n",
       "      <th>CSI</th>\n",
       "      <th>CVI</th>\n",
       "      <th>MaxNN</th>\n",
       "      <th>MinNN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.494157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.773662</td>\n",
       "      <td>213.743424</td>\n",
       "      <td>11.208240</td>\n",
       "      <td>0.156375</td>\n",
       "      <td>0.028874</td>\n",
       "      <td>2.388920</td>\n",
       "      <td>1.239546</td>\n",
       "      <td>0.529199</td>\n",
       "      <td>313.007851</td>\n",
       "      <td>198.367641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.745654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.864150</td>\n",
       "      <td>176.218008</td>\n",
       "      <td>11.862371</td>\n",
       "      <td>0.277030</td>\n",
       "      <td>0.034680</td>\n",
       "      <td>2.021418</td>\n",
       "      <td>1.619465</td>\n",
       "      <td>0.582844</td>\n",
       "      <td>225.884906</td>\n",
       "      <td>149.897395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id  segment_lenInSec      MeanNN    MedianNN      pnn20  \\\n",
       "Labels                                                                   \n",
       "0       29.494157               0.0  214.773662  213.743424  11.208240   \n",
       "1       31.745654               0.0  175.864150  176.218008  11.862371   \n",
       "\n",
       "          sd1sd2      CvNN       HTI       CSI       CVI       MaxNN  \\\n",
       "Labels                                                                 \n",
       "0       0.156375  0.028874  2.388920  1.239546  0.529199  313.007851   \n",
       "1       0.277030  0.034680  2.021418  1.619465  0.582844  225.884906   \n",
       "\n",
       "             MinNN  \n",
       "Labels              \n",
       "0       198.367641  \n",
       "1       149.897395  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_90count.groupby('Labels').std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
